---
title: "ML_Project_Assignment 2"
author: "Akitha Pinisetti"
date: "2023-02-20"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Assignment 2**
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
**Hierachical Clustering and Association Rule Mining**
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```{r}
library(arules)
transactions <- read.transactions("C:/Users/akith/Desktop/Machine Learning/transactions_data.csv", format = "basket", rm.duplicates = FALSE, cols = NULL, sep = ",")
```
## Association Rule Mining
```{r}
rules <- arules::apriori(transactions, parameter = list(support = 0.025, confidence = 0.03, minlen = 2))
inspect(rules)
```

## Rules based on Confidence
```{r}
SortRules_Conf <- sort(rules, by = 'confidence', decreasing = TRUE)
inspect(SortRules_Conf[1:15])
```
## Rules based on Lift
```{r}
SortRules_Lift <- sort(rules, by = 'lift', decreasing = TRUE)
inspect(SortRules_Lift[1:15])
```
## Rules based on Support
```{r}
SortRules_Sup <- sort(rules, by = 'support', decreasing = TRUE)
inspect(SortRules_Sup[1:15])
```
```{r}
library(arulesViz)
plot(SortRules_Conf, method="graph", engine="interactive", limit = 15)
```
```{r}
library(arulesViz)
plot(SortRules_Lift, method="graph", engine="interactive", limit = 30)
```

```{r}
library(arulesViz)
plot(SortRules_Sup, method="graph", engine="htmlwidget", limit = 30)
```


## Implementing K-Means where K=4
```{r}
num_data <- read.csv("C:/Users/akith/Desktop/Machine Learning/numeric_df.csv")
scaled_data <- scale(num_data[,1:5])
km <- kmeans(scaled_data, centers = 4, nstart = 25)
```

## Visulizing k-means
```{r}
library(readr)
library(cluster)
library(proxy)
library(factoextra)
library(ggplot2)
factoextra::fviz_cluster(km, data = scaled_data, geom = "point", ellipse.type = "convex")
```

# Hierarchical Clustering

## Sampling numeric data
```{r}
sample = num_data[seq(150,200, by = 5),]
sample_scaled <- scale(sample)
```

## Calculating distance matrices based on Euclidean, Canberra and Manhattan methods
```{r}
distMatrix_E <- dist(sample_scaled, method="euclidean")
distMatrix_Mi <- dist(sample_scaled, method="minkowski", p =3)
distMatrix_M <- dist(sample_scaled, method="manhattan")
cosine_sim <- 1 - dist(sample_scaled, method = "cosine")
```

## Hierarchical clustering based on Euclidean distance
```{r}
## Euclidean
groups_E <- hclust(distMatrix_E,method="ward.D")
plot(groups_E, cex=0.9, hang=-1, main = "Euclidean")
rect.hclust(groups_E, k=3)
```
## Hierarchical clustering based on Minkowski distance
```{r}
## Minkowski
groups_Mi <- hclust(distMatrix_Mi,method="ward.D")
plot(groups_Mi, cex=0.9, hang=-1, main = "Minkowski")
rect.hclust(groups_Mi, k=3)
```
## Hierarchical clustering based on Manhattan distance
```{r}
## Manhattan
groups_M <- hclust(distMatrix_M,method="ward.D2")
plot(groups_M, cex=0.9, hang=-1, main = "Manhattan")
rect.hclust(groups_M, k=3)
```
## Hierarchical clustering based on Cosine Similarity 
```{r}
## Cosine
groups_c <- hclust(as.dist(cosine_sim),method="ward.D2")
plot(groups_c, cex=0.9, hang=-1, main = "Cosine")
rect.hclust(groups_c, k=3)
```

```{r}
df <- read.csv("C:/Users/akith/Desktop/Machine Learning/df.csv")
```



```{r}
# References:-
# https://gatesboltonanalytics.com/?page_id=266
# https://thispointer.com/pandas-delete-last-column-of-dataframe-in-python/
# https://towardsdatascience.com/how-to-export-pandas-dataframe-to-csv-2038e43d9c03
# https://www.jdatalab.com/data_science_and_data_mining/2018/10/15/association-rule-read-transactions.html
# https://www.geeksforgeeks.org/association-rule-mining-in-r-programming/
```
